Using arpa instead of binary LM file, decoder instantiation might be slow.
Alphabet determined to be of regular style.
DeepSpeech2Model(
  (conv): Sequential(
    (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 2), padding=(10, 5))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(32, 96, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5))
    (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (rnns): Sequential(
    (0): RNNwBatchNorm(
      (rnn): GRU(3072, 512, dropout=0.2, bidirectional=True)
      (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RNNwBatchNorm(
      (rnn): GRU(512, 512, dropout=0.2, bidirectional=True)
      (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RNNwBatchNorm(
      (rnn): GRU(512, 512, dropout=0.2, bidirectional=True)
      (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RNNwBatchNorm(
      (rnn): GRU(512, 512, dropout=0.2, bidirectional=True)
      (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RNNwBatchNorm(
      (rnn): GRU(512, 512, dropout=0.2, bidirectional=True)
      (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RNNwBatchNorm(
      (rnn): GRU(512, 512, dropout=0.2, bidirectional=True)
      (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (fc): Linear(in_features=512, out_features=28, bias=True)
  (softmax): Softmax(dim=2)
)
Trainable parameters: 27757148
Loading checkpoint: default_test_model/checkpoint.pth ...
argmax_wer_mean:
38.30325956967207
beam_search_wer_mean:
37.79319491349872
lm_wer_mean:
25.746270502377914
